{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0805735b0cad371bf8d84877e4fcfacd6fad020d4fcf8a35b13b73228cee95f2c",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "805735b0cad371bf8d84877e4fcfacd6fad020d4fcf8a35b13b73228cee95f2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyquil.simulation.matrices import I, X, Y, Z\n",
    "import numpy as np\n",
    "from forest.benchmarking.operator_tools import kraus2pauli_liouville\n",
    "from print_large import _print_big_matrix\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "#gateset1 [1, 9601, 8129, 3103, 2296, 0, 0, 9285, 8118, 2974, 3058, 0, 0, 10523, 9788]\n",
    "#gateset2 [16192, 11846, 15055, 13880, 10476, 10481]\n",
    "###rb_seq_deompose\n",
    "with open('rb_seq_decompose_gateset1.pkl', 'rb') as f:\n",
    "    rb_seq_decompose = pickle.load(f)\n",
    "###primitive gate PTM\n",
    "with open('P_PTM_gateset1.pkl', 'rb') as f:\n",
    "    P_PTM = pickle.load(f)\n",
    "#### 2-qubit pauli basis\n",
    "pauli_basis=[np.asarray(np.kron(i,j)) for i in [I, X, Y, Z] for j in [I, X, Y, Z]]\n",
    "#### 2-qubit |0> and |1>\n",
    "e_state=np.kron(np.asarray([[0,0],[0,1]]),np.asarray([[0,0],[0,1]]))\n",
    "g_state=np.kron(np.asarray([[1,0],[0,0]]),np.asarray([[1,0],[0,0]]))\n",
    "####Density matrix to PTM\n",
    "def densityop_01_2_pauli(density_op):\n",
    "    #assert density_op.ndim !=4,'wrong dim'\n",
    "    A=np.asarray([np.trace(density_op@i_den) for i_den in pauli_basis]).reshape(density_op.size,1)\n",
    "    return A\n",
    "def densityop_pauli_2_01(density_op):\n",
    "    #assert density_op.shape == (len(density_op),1),'wrong dim'\n",
    "    A_den=np.asarray([density_op[i_den]*pauli_basis[i_den] for i_den in range(16)])\n",
    "    B_den=np.zeros((4,4))\n",
    "    for i_den in A_den:\n",
    "        B_den=B_den+i_den\n",
    "    return B_den/4\n",
    "def dephaseing_PTM(p):\n",
    "    A=[np.kron(i_deph,j_deph) for i_deph in [I,Z] for j_deph in [I,Z]]\n",
    "    for i_deph in [0]:\n",
    "        A[i_deph] = A[i_deph]*np.sqrt(p+(1-p)/4)\n",
    "    for i_deph in [1,2,3]:\n",
    "        A[i_deph] = A[i_deph]*np.sqrt((1-p)/4)\n",
    "#########kraus to PTM \n",
    "    return kraus2pauli_liouville(A)\n",
    "def depolarizing_PTM(p):\n",
    "    A=[np.kron(i_depo,j_depo) for i_depo in [I,X,Y,Z] for j_depo in [I,X,Y,Z]]\n",
    "    A[0] = A[0]*np.sqrt(1-15*p/16)\n",
    "    for i_depo in range(1,len(A)):\n",
    "        A[i_depo]=A[i_depo]*np.sqrt(p/16)\n",
    "#########kraus to PTM        \n",
    "    return kraus2pauli_liouville(A)\n",
    "def sequence_to_probability(_rb_seq):\n",
    "####initial state    \n",
    "    _state=densityop_01_2_pauli(g_state)\n",
    "####depo or deph=  noise channel @ Cliff @ state\n",
    "    if noise_channel==0:\n",
    "        for _i in _rb_seq :\n",
    "            _state=depolarizing_PTM(noise_strength)@P_PTM[_i]@_state\n",
    "    elif noise_channel==1:\n",
    "        for _i in _rb_seq :\n",
    "            _state=dephaseing_PTM(noise_strength)@P_PTM[_i]@_state\n",
    "####get [00] prob\n",
    "    return np.real(densityop_pauli_2_01(_state)[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dephaseing_PTM' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-376e81415733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdephaseing_PTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dephaseing_PTM' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "####### input\n",
    "    rb_types=int(input('-1 rb, 0 decomp_rb, 1 prb\\n'))\n",
    "    max_seq= int(input('max seq \\n'))\n",
    "    noise_channel= int(input('depolarizing (0) or dephasing (1) \\n'))\n",
    "    noise_strength= float(input('noisy(0)-----(1)noiseless\\n'))\n",
    "####### rb gate number i    \n",
    "    for i in tqdm([i for i in range(1,max_seq)],ascii=True,desc=\"sequence_length\",dynamic_ncols=True):\n",
    "####### rb sequence into probablility\n",
    "        m_average=[]\n",
    "        pool = mp.Pool()\n",
    "        repeat_probability = pool.map(sequence_to_probability,rb_seq_decompose[i])\n",
    "        pool.close()\n",
    "        pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  \n .   .   .   .   .   .  -1.0  .   .   .   .   .   .   .   .   .  \n .   .   .   .   .   .   .   .   .   .   .   .  1.0  .   .   .  \n .   .   .   .   .   .   .   .   .   .  1.0  .   .   .   .   .  \n .   .   .   .   .   .   .   .   .   .   .   .   .  -1.0  .   .  \n .   .   .   .   .   .   .   .   .   .   .  -1.0  .   .   .   .  \n .  -1.0  .   .   .   .   .   .   .   .   .   .   .   .   .   .  \n .   .   .   .   .   .   .  -1.0  .   .   .   .   .   .   .   .  \n .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  1.0 \n .   .   .   .   .   .   .   .   .  -1.0  .   .   .   .   .   .  \n .   .   .  1.0  .   .   .   .   .   .   .   .   .   .   .   .  \n .   .   .   .   .  -1.0  .   .   .   .   .   .   .   .   .   .  \n .   .  1.0  .   .   .   .   .   .   .   .   .   .   .   .   .  \n .   .   .   .  -1.0  .   .   .   .   .   .   .   .   .   .   .  \n .   .   .   .   .   .   .   .   .   .   .   .   .   .  1.0  .  \n .   .   .   .   .   .   .   .  1.0  .   .   .   .   .   .   .  \n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "if __name__ == '__main__':\n",
    "\n",
    "####### input\n",
    "    rb_types=-1\n",
    "\n",
    "    noise_channel= 0\n",
    "    noise_strength= 1\n",
    "####### rb gate number i \n",
    "    reg=P_PTM[9]\n",
    "    for i in [ 14, 8, 7, 2, 1, 9, 14, 8, 7, 2, 1]:\n",
    "       reg= P_PTM[i]@reg\n",
    "    \n",
    "    _print_big_matrix(reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import pickle\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "with open('Cliff_index_gateset1.pkl', 'rb') as f:\n",
    "    old_Cliff_index_gateset = pickle.load(f)\n",
    "with open('Cliff_kruas.pkl', 'rb') as f:\n",
    "    Cliff_kruas = pickle.load(f)\n",
    "with open('P_kruas_gateset1.pkl', 'rb') as f:\n",
    "    P_kruas_gateset = pickle.load(f)\n",
    "\n",
    "def reindex(i):\n",
    "### first matrix\n",
    "    _reg=np.eye(4)\n",
    "### else matrix    \n",
    "    for j in old_Cliff_index_gateset[i]:\n",
    "        _reg=P_kruas_gateset[j]@_reg\n",
    "### new [j]   = old [i] \n",
    "    for j in range(11520):\n",
    "        if np.isclose(np.trace(_reg@np.conj(Cliff_kruas[j]).T)/4,1):\n",
    "            new_Cliff_index_gateset[j]=old_Cliff_index_gateset[i]   \n",
    "            break\n",
    "if __name__ == '__main__':\n",
    "    ###reindex\n",
    "    new_Cliff_index_gateset=[False]*11520\n",
    "    pool = mp.Pool()\n",
    "    pool.map_async(reindex,[i for i in range(11520)])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    with open('Cliff_index_gateset1.pkl', 'wb') as f:\n",
    "        pickle.dump(new_Cliff_index_gateset, f)\n"
   ]
  }
 ]
}